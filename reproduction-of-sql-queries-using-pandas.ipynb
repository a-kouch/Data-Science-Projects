{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "172af7e6-1103-4ca6-b6cf-47681c9a41f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reproduction of SQL queries using Pandas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f5614-dfff-4092-8755-b020adb16e84",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "Understand use and interpretation of Structured Query Language (SQL) queries and reproducing their outputs using Python and the Pandas package. A variety of datasets were used, containing 336,776 flights that departed in 2013 from three New York airports (EWR, JFK and LGA). The datasets used included flight information, two letter carrier codes, airport data, plane data and hourly meteorological data for the three airports. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7113dad-b113-4bcd-b510-47d3f2c3ff34",
   "metadata": {},
   "source": [
    "Dataset obtained from https://nycflights13.tidyverse.org/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151c889-4d30-467f-8963-89f693bc09a1",
   "metadata": {},
   "source": [
    "Create a connection object and create the .db file.\n",
    "\n",
    "Create a table within the database using the DataFrame with the `.to_sql()` method.\n",
    "\n",
    "Now that the data has been exported, we can issue SQL queries with `pd.read_sql_query()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadd95fc-5bd3-401c-86bb-c3a93a05f20c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.notebook_repr_html\", False)  # disable \"rich\" output\n",
    "\n",
    "formats = \"ipynb,py:percent\"\n",
    "\n",
    "# Read csv files as a dataframe\n",
    "flights = pd.read_csv(\"flights.csv\", comment=\"#\")\n",
    "airlines = pd.read_csv(\"airlines.csv\", comment=\"#\")\n",
    "airports = pd.read_csv(\"airports.csv\", comment=\"#\")\n",
    "planes = pd.read_csv(\"planes.csv\", comment=\"#\")\n",
    "weather = pd.read_csv(\"weather.csv\", comment=\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c6b286-3abd-475a-8be3-bf524b6127e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
       "0  2013      1    1     517.0             515        2.0     830.0   \n",
       "1  2013      1    1     533.0             529        4.0     850.0   \n",
       "2  2013      1    1     542.0             540        2.0     923.0   \n",
       "3  2013      1    1     544.0             545       -1.0    1004.0   \n",
       "4  2013      1    1     554.0             600       -6.0     812.0   \n",
       "\n",
       "   sched_arr_time  arr_delay carrier  flight tailnum origin dest  air_time  \\\n",
       "0             819       11.0      UA    1545  N14228    EWR  IAH     227.0   \n",
       "1             830       20.0      UA    1714  N24211    LGA  IAH     227.0   \n",
       "2             850       33.0      AA    1141  N619AA    JFK  MIA     160.0   \n",
       "3            1022      -18.0      B6     725  N804JB    JFK  BQN     183.0   \n",
       "4             837      -25.0      DL     461  N668DN    LGA  ATL     116.0   \n",
       "\n",
       "   distance  hour  minute            time_hour  \n",
       "0      1400     5      15  2013-01-01 05:00:00  \n",
       "1      1416     5      29  2013-01-01 05:00:00  \n",
       "2      1089     5      40  2013-01-01 05:00:00  \n",
       "3      1576     5      45  2013-01-01 05:00:00  \n",
       "4       762     6       0  2013-01-01 06:00:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a5c800-fd20-4af3-aee8-a7f776c617e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\tmpkt7dmn_p\\sql_and_pandas.db\n"
     ]
    }
   ],
   "source": [
    "import tempfile, os.path\n",
    "dbfile = os.path.join(tempfile.mkdtemp(), \"sql_and_pandas.db\")\n",
    "print(dbfile)\n",
    "conn = sqlite3.connect(dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f603a24-a171-41db-a874-4ad1a70ec817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26130"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.to_sql(\"flights\", conn, index=False)\n",
    "airlines.to_sql(\"airlines\", conn, index=False)\n",
    "airports.to_sql(\"airport\", conn, index=False)\n",
    "planes.to_sql(\"planes\", conn, index=False)\n",
    "weather.to_sql(\"weather\", conn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f27453b-94b0-4f3d-bbea-0d039d6de85c",
   "metadata": {},
   "source": [
    "## Query 1\n",
    "The SQL query returns all unique values from the 'engine' column in the 'planes' table, removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fcd930-e30d-4cfc-9132-24faa92d8256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 1\n",
    "query_1_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT DISTINCT engine FROM planes\n",
    "\"\"\", conn)\n",
    "\n",
    "query_1_p = planes.loc[:, [\"engine\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "pd.testing.assert_frame_equal(query_1_sql, query_1_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a71ba-8087-4c6c-a4a9-d6ef47384a7a",
   "metadata": {},
   "source": [
    "In Pandas we filter out all rows from the 'engine' column of the 'planes' DataFrame and use the .drop_duplicates() method to obtain all unique values.\n",
    "\n",
    "\n",
    "## Query 2 \n",
    "This SQL query returns all unique values from the 'engine' and 'type' columns in the 'planes' table, removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b504e015-f19a-4155-9752-793a660a260e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 2\n",
    "query_2_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT DISTINCT type, engine FROM planes\n",
    "\"\"\", conn)\n",
    "\n",
    "query_2_p = planes.loc[:, [\"type\", \"engine\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "pd.testing.assert_frame_equal(query_2_sql, query_2_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f5c2e-aff4-421d-a959-b2351890fed0",
   "metadata": {},
   "source": [
    "In Pandas we filtered out all rows from the 'engine' and 'type' columns of the 'planes' DataFrame and use the .drop_duplicates() method to obtain all unique values.\n",
    "\n",
    "## Query 3\n",
    "\n",
    "This SQL query selects the 'engine' column from the 'planes' table and 'COUNT(\\*)' is used to count the number of rows in each group. The 'GROUP BY' clause groups the rows based on distinct values in the 'engine' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32064963-132c-465d-9a68-4068f45343da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 3\n",
    "query_3_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT COUNT(*), engine FROM planes GROUP BY engine\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_3_p = planes.groupby(\"engine\", as_index=False).size()\n",
    "# Re-name columns\n",
    "query_3_p.columns= [\"engine\", \"COUNT(*)\"]\n",
    "# Re-order columns\n",
    "query_3_p = query_3_p[[\"COUNT(*)\", \"engine\"]]\n",
    "\n",
    "pd.testing.assert_frame_equal(query_3_sql, query_3_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2794423-94a0-4185-974e-18563331993a",
   "metadata": {
    "tags": []
   },
   "source": [
    "In Pandas we use .groupby().size() on the planes DataFrame to get a count of each distinct type of engine\n",
    "\n",
    "We then need to re-name and re-order the columns to match the SQL query.\n",
    "\n",
    "## Query 4\n",
    "\n",
    "This SQL query creates a table containing each unique combination of 'engine' and 'type' from the 'planes table' and includes a count of the number of occurences for each combination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9694ff4-f7e2-49d0-91fa-0755d2efecdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 4\n",
    "query_4_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT COUNT(*), engine, type FROM planes\n",
    "GROUP BY engine, type\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_4_p = planes.groupby([\"engine\", \"type\"], as_index=False).size()\n",
    "# Re-name columns\n",
    "query_4_p.columns= [\"engine\", \"type\", \"COUNT(*)\"]\n",
    "# Re-order columns\n",
    "query_4_p = query_4_p[[\"COUNT(*)\", \"engine\", \"type\"]]\n",
    "\n",
    "pd.testing.assert_frame_equal(query_4_sql, query_4_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6502f5f1-04f7-4fc0-8893-4b4de812f58e",
   "metadata": {
    "tags": []
   },
   "source": [
    "In Pandas we use group the DataFrame by 'engine' and 'type' to get all unique combinations and use .size() to obtain a count of their occurences.\n",
    "Again we have to re-name and re-order the columns to match the SQL output.\n",
    "\n",
    "## Query 5\n",
    "This SQL query calculates the minimum, average and maximum values of the 'year' column' for each unique combination of 'engine' and 'manufacturer' in the 'planes' table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "819252e7-7044-4534-93d2-ae4003d5a4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 5\n",
    "query_5_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT MIN(year), AVG(year), MAX(year), engine, manufacturer\n",
    "    FROM planes\n",
    "    GROUP BY engine, manufacturer\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_5_p = planes.loc[:, [\"engine\", \"manufacturer\", \"year\"]].groupby([\"engine\", \"manufacturer\"])[\"year\"].aggregate([np.min, np.mean, np.max]).reset_index()\n",
    "\n",
    "# Re-name columns\n",
    "query_5_p.columns = [\"engine\", \"manufacturer\", \"MIN(year)\", \"AVG(year)\", \"MAX(year)\"]\n",
    "\n",
    "# Re-order columns\n",
    "query_5_p = query_5_p[[\"MIN(year)\", \"AVG(year)\", \"MAX(year)\", \"engine\", \"manufacturer\"]]\n",
    "\n",
    "pd.testing.assert_frame_equal(query_5_sql, query_5_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c89c02-3e11-41c4-8e59-a23180fb0582",
   "metadata": {
    "tags": []
   },
   "source": [
    "In Pandas we filter out the 'engine', 'manufacturer' and 'year' columns from the 'planes' DataFrame and .groupby() 'engine' and 'manufacturer' to get all unique combinations of these columns. \n",
    "\n",
    "We can then use .aggregate() to obtain the minimum, mean and maxmimum of the year for each unique combination.\n",
    "\n",
    "## Query 6\n",
    "This SQL query returns all columns and rows in the 'planes' table where the 'speed' column has a non-NULL value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "251b77c1-d618-4aff-bd43-a6c31f91d175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 6\n",
    "query_6_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT * FROM planes WHERE speed IS NOT NULL\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_6_p = planes.loc[~planes.speed.isna(), :].reset_index(drop=True)\n",
    "\n",
    "pd.testing.assert_frame_equal(query_6_sql, query_6_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b616d4b-cb0e-4d47-b0d0-ba8f1aa28f78",
   "metadata": {
    "tags": []
   },
   "source": [
    "In Pandas we filter out all rows from all columns where speed is not (~), NULL (.isna()) \n",
    "\n",
    "## Query 7\n",
    "This SQL query returns the 'tailnum' values from the 'planes' table for aircraft that had the seating capacity between 150 and 210 inclusive and where the year was greater than or equal to 2011.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0715e50d-52d0-4fa9-841a-34c088f6b330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 7\n",
    "query_7_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT tailnum FROM planes\n",
    "    WHERE seats BETWEEN 150 AND 210 AND year >= 2011\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_7_p = planes.loc[(planes.seats >= 150) & (planes.seats <= 210) & (planes.year >= 2011), [\"tailnum\"]].reset_index(drop=True)\n",
    "\n",
    "pd.testing.assert_frame_equal(query_7_sql, query_7_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb9017-49f4-4a02-9ded-799260301408",
   "metadata": {},
   "source": [
    "\n",
    "In Pandas we filter out rows where: seats >=150 and seats <= 210 and year >= 2011 from the 'tailnum' column of the 'planes' DataFrame.\n",
    "\n",
    "## Query 8\n",
    "\n",
    "This SQL query returns the 'tailnum', 'manufacturer' and 'seats' columns from the 'planes' table where the manufacturer was Boeing, Airbus or Embraer and had more than 390 seats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec7b182e-9261-4667-b536-0e1692277480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 8\n",
    "query_8_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT tailnum, manufacturer, seats FROM planes\n",
    "    WHERE manufacturer IN (\"BOEING\", \"AIRBUS\", \"EMBRAER\") AND seats>390\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_8_p = (\n",
    "    planes.loc[(planes.manufacturer.isin(['BOEING', 'AIRBUS', 'EMBRAER'])) & \n",
    "               (planes.seats > 390), \n",
    "               [\"tailnum\", \"manufacturer\", \"seats\"]].\n",
    "    reset_index(drop=True)\n",
    ")\n",
    "\n",
    "pd.testing.assert_frame_equal(query_8_sql, query_8_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc07146-969d-4fd8-b8a0-93f323fe502a",
   "metadata": {
    "tags": []
   },
   "source": [
    "In Pandas we filter out rows that contain 'BOEING', 'AIRBUS' and 'EMBRAER' and had more than 390 seats from the 'tailnum', 'manufacturer' and 'seats' columns of the 'planes' DataFrame.\n",
    "\n",
    "## Query 9\n",
    "\n",
    "This SQL query returns distinct combinations of 'year' and 'seats' from the 'planes' table for planes with the year greater than or equal to 2012. \n",
    "This query is also sorted by ascending year and descending seats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c12ba953-4238-492b-8362-7ce8adad8275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 9\n",
    "query_9_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT DISTINCT year, seats FROM planes\n",
    "    WHERE year >= 2012 ORDER BY year ASC, seats DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_9_p = (\n",
    "    planes.loc[(planes.year >= 2012), \n",
    "              [\"year\", \"seats\"]].sort_values([\"year\", \"seats\"], ascending=[True, False])\n",
    "    .drop_duplicates().reset_index(drop=True)\n",
    ")\n",
    "\n",
    "pd.testing.assert_frame_equal(query_9_sql, query_9_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6cc2b4-d432-456d-9dd5-32eba1c65943",
   "metadata": {},
   "source": [
    "In Pandas we filter out rows that have 'year' greater than or equal to 2012 from the 'year' and 'seat' column of the 'planes' table.\n",
    "We can then .sort_values() by 'year' and 'seats' by ascending and descending respectively and remove duplicates with .drop_duplicates.\n",
    "\n",
    "## Query 10\n",
    "This SQL query returns all distinct combinations of 'year' and 'seats' from the 'planes' table for which aircraft had the year 2012 or higher. \n",
    "The results are ordered by 'seats' in descending order and 'year' in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bddba61-a90b-4800-8705-a9ae1919f9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 10\n",
    "query_10_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT DISTINCT year, seats FROM planes\n",
    "    WHERE year >= 2012 ORDER BY seats DESC, year ASC\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_10_p = (\n",
    "    planes.loc[(planes.year >= 2012), \n",
    "              [\"year\", \"seats\"]].sort_values([\"seats\", \"year\"], ascending=[False, True])\n",
    "    .drop_duplicates().reset_index(drop=True)\n",
    ")\n",
    "\n",
    "pd.testing.assert_frame_equal(query_10_sql, query_10_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf6852d-4ff1-4fab-a673-10df87352638",
   "metadata": {},
   "source": [
    "In Pandas we filter out rows that have 'year' greater than or equal to 2012 from the 'year' and 'seat' column of the 'planes' table.\n",
    "We can then .sort_values() by 'seats' and 'year' by descending and ascending respectively and remove duplicates with .drop_duplicates.\n",
    "\n",
    "## Query 11\n",
    "This SQL query counts the number of planes with more than 200 seats for each unique 'manufacturer' from the 'planes' table. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72437ce-9473-4604-a13d-cd4dde2ff6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 11\n",
    "query_11_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) FROM planes\n",
    "    WHERE seats > 200 GROUP BY manufacturer\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_11_p = planes.loc[(planes.seats > 200), :].groupby(\"manufacturer\", as_index=False).size()\n",
    "# Re-name columns\n",
    "query_11_p.columns = [\"manufacturer\", \"COUNT(*)\"]\n",
    "\n",
    "pd.testing.assert_frame_equal(query_11_sql, query_11_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b83442-8c19-4a95-af4f-de17cf10795f",
   "metadata": {
    "tags": []
   },
   "source": [
    "In Pandas we filter out all rows with seats greater than 200 and use .groupby().size() manufacturer to get a count.\n",
    "We also re-name the columns to match the SQL query.\n",
    "\n",
    "## Query 12\n",
    "This SQL query counts the number of planes for each unique manufacturer in the 'planes' table and only returns manufacturers that have counts greater than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66ae3057-f499-4a07-af3c-f44282902898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 12\n",
    "query_12_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) FROM planes\n",
    "    GROUP BY manufacturer HAVING COUNT(*) > 10\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_12_p = planes.groupby(\"manufacturer\", as_index=False).size()\n",
    "# Re-name size as it is the same name the size function, avoid using COUNT(*) as it also has poor interactions\n",
    "query_12_p.columns = [\"manufacturer\", \"count_placeholder\"]\n",
    "# Filter for count_placeholder > 10\n",
    "query_12_p = query_12_p.loc[(query_12_p.count_placeholder > 10), :].reset_index(drop=True)\n",
    "# Re-name columns\n",
    "query_12_p.columns = [\"manufacturer\", \"COUNT(*)\"]\n",
    "\n",
    "pd.testing.assert_frame_equal(query_12_sql, query_12_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969c0d1-a056-451d-952c-de6a43a1f326",
   "metadata": {},
   "source": [
    "In Pandas we groupby manufacturer to get unique manufacturers and size() to get a count.\n",
    "We then filter by rows greater than 10 and rename the columns to match the original query.\n",
    "\n",
    "## Query 13\n",
    "This SQL query counts the number of planes for each unique manufacturer in the 'planes' table and only returns manufacturers that have seats greater than 200 and also for which manufacturers have a count greater than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ffa5578-02c7-41de-b165-8c917b5b8c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 13\n",
    "query_13_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) FROM planes\n",
    "    WHERE seats > 200 GROUP BY manufacturer HAVING COUNT(*) > 10\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_13_p = planes.loc[(planes.seats > 200), :].groupby(\"manufacturer\", as_index=False).size()\n",
    "# Re-name size as it is the same name the size function, avoid using COUNT(*) as it also has poor interactions\n",
    "query_13_p.columns = [\"manufacturer\", \"count_placeholder\"]\n",
    "# Filter for count_placeholder > 10\n",
    "query_13_p = query_13_p.loc[(query_13_p.count_placeholder > 10), :].reset_index(drop=True)\n",
    "# Re-name columns\n",
    "query_13_p.columns = [\"manufacturer\", \"COUNT(*)\"]\n",
    "\n",
    "pd.testing.assert_frame_equal(query_13_sql, query_13_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d4d6e4-13b8-425f-bb57-e95bb1c833f3",
   "metadata": {},
   "source": [
    "In Pandas we filter out rows that have seats greater than 200 and group by 'manufacturer' and use .size() to get a count of 'manufacturer'.\n",
    "Of this we can then filter again to get counts that are greater than 10 and ren-name the columns to match the original query.\n",
    "\n",
    "## Query 14\n",
    "This SQL query counts the number of planes for each unique 'manufactuer' from the 'planes' table. It assigns the alias 'howmany' to the count column.\n",
    "The top 10 results are ordered by descending count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "122f740e-fba9-4427-adb6-ed617d390c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 14\n",
    "query_14_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) AS howmany\n",
    "    FROM planes\n",
    "    GROUP BY manufacturer\n",
    "    ORDER BY howmany DESC LIMIT 10\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "query_14_p = planes.groupby(\"manufacturer\", as_index=False).size()\n",
    "# Rename columns\n",
    "query_14_p.columns = [\"manufacturer\", \"howmany\"]\n",
    "# Sort by \"howmany\" and get top 10 results\n",
    "query_14_p = query_14_p.sort_values(\"howmany\", ascending=False).head(10).reset_index(drop=True)\n",
    "\n",
    "pd.testing.assert_frame_equal(query_14_sql, query_14_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdd392-02bc-4339-84fb-2a45965748e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "In Pandas we first get the count of unique manufacturer's by using .groupby() and .size().\n",
    "We can rename the columns to rename the count column to 'howmany' then use .sortvalues().head() to sort by descending 'howmany' and get the top 10 results.\n",
    "\n",
    "## Query 15\n",
    "This SQL query retrieves all columns from the 'flights' table as we as the 'year', 'speed' and 'seats' columns from the 'planes' table under the alias 'plane_year', 'plane_speed' and 'plane_seats'. \n",
    "The query then performs a left join on the 'flights' table with 'planes' using 'tailnum' as the key.\n",
    "The left join returns all records from the 'flights' table with matches from the 'planes' table, if there is no match then it will insert NULL's in the columns of the 'planes' table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ff24fc-9e9f-4764-b357-95b1b93cc5e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 15\n",
    "query_15_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT\n",
    "        flights.*,\n",
    "        planes.year AS plane_year,\n",
    "        planes.speed AS plane_speed,\n",
    "        planes.seats AS plane_seats\n",
    "    FROM flights LEFT JOIN planes ON flights.tailnum=planes.tailnum\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "# Filter planes DataFrame to required columns \n",
    "planes_modified = planes.loc[:, [\"tailnum\", \"year\", \"speed\", \"seats\"]]\n",
    "# Re-name columns\n",
    "planes_modified.columns = [\"tailnum\", \"plane_year\", \"plane_speed\", \"plane_seats\"]\n",
    "# Merge both DataFrames with a left join\n",
    "query_15_p = pd.merge(flights, planes_modified, on=\"tailnum\", how='left')\n",
    "\n",
    "pd.testing.assert_frame_equal(query_15_sql, query_15_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f76a8-f7d3-47d0-bb12-7365487c3e1f",
   "metadata": {},
   "source": [
    "In Pandas we filter from the 'planes' DataFrame the columns for 'tailnum', 'year', 'speed' and 'seats' and re-name their columns.\n",
    "Then we can perform the left join with pd.merge() on 'tailnum'.\n",
    "\n",
    "## Query 16 \n",
    "This SQL query retrieves all columns from 'planes' and 'airlines' tables for rows that have a match on 'tailnum' in the 'planes' table and 'carrier' in the 'airlines' table with the distinct combinations found from the 'flights' table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cdf8d19-543d-426d-b59f-c68498d98d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 16\n",
    "query_16_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT planes.*, airlines.* FROM\n",
    "    (SELECT DISTINCT carrier, tailnum FROM flights) AS cartail\n",
    "    INNER JOIN planes ON cartail.tailnum=planes.tailnum\n",
    "    INNER JOIN airlines ON cartail.carrier=airlines.carrier\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "cartail = flights.loc[:, [\"tailnum\", \"carrier\"]].drop_duplicates()\n",
    "query_16_p = pd.merge(planes, cartail, on=\"tailnum\", how='inner')\n",
    "query_16_p = pd.merge(query_16_p, airlines, on=\"carrier\", how='inner')\n",
    "\n",
    "# # Re-order columns\n",
    "query_16_p = query_16_p[[\"tailnum\", \"year\", \"type\", \"manufacturer\", \"model\", \"engines\", \"seats\", \"speed\", \"engine\", \"carrier\", \"name\"]]\n",
    "query_16_p = query_16_p.sort_values([\"tailnum\", \"carrier\"]).reset_index(drop=True)\n",
    "\n",
    "pd.testing.assert_frame_equal(query_16_sql, query_16_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7483f0-8dea-43b7-83b7-01d83af4d5b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "In Pandas we create a DataFrame called 'cartail' that contains the 'tailnum' and 'carrier' columns from the 'flights' table. \n",
    "Using .drop_duplicates removes all duplicates.\n",
    "We then perform an inner join on the 'planes' DataFram with the 'cartail' DataFrame using 'tailnum' as the primary key. \n",
    "Then another inner join on this new DataFrame with the 'airlines' DataFrame using 'carrier' as the primary key.\n",
    "We then re-order the columns and sort by 'tailnum' and 'carrier' to match the original query.\n",
    "\n",
    "\n",
    "## Query 17\n",
    "This SQL query retrieves creates a table that has flights from the origin 'EWR' from the 'flights' table under the alias 'flights2'.\n",
    "It also creates another table called 'weather2' that contains the 'year', 'month', 'day' as well as the average temperature and humidity under the alias 'atemp' and 'ahumid' respectively, from the 'weather' table.\n",
    "It then performs a left join on 'flights2' with 'weather2' using 'year', 'month' and 'day' as the primary keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c3e925f-383a-4644-abbf-b7a8a9611753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query 17\n",
    "query_17_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT\n",
    "        flights2.*,\n",
    "        atemp,\n",
    "        ahumid\n",
    "    FROM (\n",
    "        SELECT * FROM flights WHERE origin='EWR'\n",
    "    ) AS flights2\n",
    "    LEFT JOIN (\n",
    "        SELECT\n",
    "            year, month, day,\n",
    "            AVG(temp) AS atemp,\n",
    "            AVG(humid) AS ahumid\n",
    "        FROM weather\n",
    "        WHERE origin='EWR'\n",
    "        GROUP BY year, month, day\n",
    "    ) AS weather2\n",
    "    ON flights2.year=weather2.year\n",
    "    AND flights2.month=weather2.month\n",
    "    AND flights2.day=weather2.day\n",
    "\"\"\", conn)\n",
    "\n",
    "# In Pandas\n",
    "# Filter flights for origin \"EWR\"\n",
    "flights2 = flights.loc[(flights.origin==\"EWR\"), :]\n",
    "\n",
    "# Filter weather for origin \"EWR\" and calculate average for temp and humidity\n",
    "weather2 = (\n",
    "    weather.loc[(weather.origin==\"EWR\"), \n",
    "                [\"year\", \"month\", \"day\", \"temp\", \"humid\"]]\n",
    "    .groupby([\"year\", \"month\", \"day\"])\n",
    "    .agg(atemp=(\"temp\", \"mean\"), ahumid=(\"humid\", \"mean\")).reset_index()\n",
    ")\n",
    "\n",
    "# Left join flight2 with weather2 \n",
    "query_17_p = pd.merge(flights2, weather2, on=[\"year\", \"month\", \"day\"], how='left')\n",
    "\n",
    "pd.testing.assert_frame_equal(query_17_sql, query_17_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3372d72-5a41-42e2-a905-60d5e358bda4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48945b61-c86d-4e56-872b-a2fe5dd9a37a",
   "metadata": {
    "tags": []
   },
   "source": [
    "In Pandas we create 'flight2' which contains the filtered results of rows that contain the origin 'EWR' from the 'flights' DataFrame.\n",
    "\n",
    "We also create 'weather2' which contains the columns 'year', 'month', 'day', 'temp' and 'humid' columns and rows that have origin 'EWR' from the 'weather' DataFrame.\n",
    "\n",
    "We then groupby 'year', 'month' and 'day' and calculate the average temperature and humidity under the column names 'atemp' and 'ahumid'.\n",
    "\n",
    "Then we can do left join on 'flights2' with 'weather2'.\n",
    "\n",
    "Lastly we can close the connection to the database since there are no more remaining tasks.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "From large datasets we are able to obtain meaningful data by filtering out data with desired conditions. This can be performed through SQL which generally can be more readable to humans but also through Pandas. \n",
    "\n",
    "We can also join different datasets as long as there is a column that we can use as a primary key that appears in both datasets.\n",
    "\n",
    "Joining two datasets can make the data more messy but also can add additional information to our pre-existing data, this all depends on how well we can work with the new combined data.\n",
    "\n",
    "Understanding how to obtain the same query through Pandas allows for deeper appreciation and understanding of the Pandas package.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
